{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ddee96f-02df-4498-842a-286026136930",
   "metadata": {},
   "source": [
    "### Канаев Байтик\n",
    "### AIN-2-21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "336806aa-c1fe-42c1-9a6a-8be1753ab6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "reviews_train = load_files(r\"C:\\Users\\beish\\JLab\\Big Data\\aclImdb\\train\")\n",
    "\n",
    "text_train, y_train = reviews_train.data, reviews_train.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8069dbd3-1d80-4acb-b6b9-6ecc3ee269ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = [doc.replace(b\"<br />\", b\" \") for doc in text_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc0f30b9-5268-40ec-8fe1-e8385ff51664",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_test = load_files(r\"C:\\Users\\beish\\JLab\\Big Data\\aclImdb\\test\")\n",
    "text_test, y_test = reviews_test.data, reviews_test.target\n",
    "text_test = [doc.replace(b\"<br />\", b\" \") for doc in text_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae2494e2-f607-40a3-a9cf-2a752ab30178",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer(max_features = 10000, max_df = .15)\n",
    "X = vect.fit_transform(text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c688ef9-0e9f-4bcb-856d-5b4f78d53c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda = LatentDirichletAllocation(n_components = 10, learning_method = \"batch\", max_iter = 10, random_state = 0)\n",
    "# Мы строим модель и преобразуем данные в один этап\n",
    "# Преобразование займет некоторое время,\n",
    "# и мы можем сэкономить время, выполнив обе операции сразу\n",
    "document_topics = lda.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00e6d6c1-8f55-47be-b897-e31198f670cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10000)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cfe6c035-056a-4597-8bb0-af308187242d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "sorting = np.argsort(lda.components_, axis = 1)[:, ::-1]\n",
    "feature_names = np.array(vect.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d393ee75-c638-4379-b247-2faa3663aef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0       topic 1       topic 2       topic 3       topic 4       \n",
      "--------      --------      --------      --------      --------      \n",
      "action        worst         plays         cast          show          \n",
      "horror        didn          comedy        role          funny         \n",
      "game          nothing       role          john          book          \n",
      "effects       horror        school        performance   saw           \n",
      "original      actually      town          star          years         \n",
      "quite         minutes       harry         young         again         \n",
      "fight         funny         played        play          10            \n",
      "lot           actors        western       music         comedy        \n",
      "however       re            joe           musical       am            \n",
      "though        going         girl          plays         dvd           \n",
      "\n",
      "\n",
      "topic 5       topic 6       topic 7       topic 8       topic 9       \n",
      "--------      --------      --------      --------      --------      \n",
      "director      guy           around        war           show          \n",
      "performance   gets          down          family        series        \n",
      "woman         wife          now           world         episode       \n",
      "between       car           kids          us            new           \n",
      "seems         action        re            young         world         \n",
      "work          police        old           father        tv            \n",
      "sex           jack          things        mother        documentary   \n",
      "role          down          monster       american      us            \n",
      "both          goes          effects       women         shows         \n",
      "real          doesn         find          our           season        \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mglearn\n",
    "\n",
    "mglearn.tools.print_topics(topics=range(10), feature_names = feature_names,\n",
    "sorting = sorting, topics_per_chunk = 5, n_words = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7123d5-5463-47c3-a2b8-8514789745cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda100 = LatentDirichletAllocation(n_components = 100, learning_method = \"batch\", max_iter = 10, random_state = 0)\n",
    "document_topics100 = lda100.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06eefd3-dc6e-4add-9bb1-03d27a491803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "topics = np.array([7,16,24,25,28,36,37,45,51,53,54,63,89,97])\n",
    "\n",
    "sorting = np.argsort(lda100.components_, axis = 1)[:, ::-1]\n",
    "feature_names = np.array(vect.get_feature_names_out())\n",
    "mglearn.tools.pring_topics(topics = topics, feature_names = feature_names, sorting = sorting, topics_per_chunk = 7, n_words = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf8fc03-26cd-4a37-b12c-40a77059c66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "music = np.argsort(document_topics100[:, :45])(::-1)\n",
    "\n",
    "for i in music[:10]:\n",
    "    print(b\"\".join(text_train[i].split(b\".\")[:2]) + b\".\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9c90f9-b9e7-4955-a3d7-890bd6855874",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1,2, figsize = (10, 10))\n",
    "topic_names = [\"{:>2}\".format(i) + \" \".join(words)\n",
    "              for i, words in enumerate(feature_names[sorting[:,:2]])]\n",
    "\n",
    "for col in [0,1]:\n",
    "    start = col * 50\n",
    "    end = (col + 1) * 50\n",
    "    ax[col].barh(np.arange(50).np.sum(document_topics100, axis = 0)[start:end])\n",
    "    ex[col].set_yticks(np.arange(50))\n",
    "    ax[col].set_yticklabels(topic_names[start:end], ha = \"left\", va = \"top\")\n",
    "    ax[col].invert_yaxis()\n",
    "    ax[col].set_xlim(0,2000)\n",
    "    yax = ax[col].get_yaxis()\n",
    "    yax.set_tick_params(pad = 130)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5235d0a8-b24f-4175-986b-1d53cbdc4cf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2cf2c260-8547-427d-90a3-0817156d1418",
   "metadata": {},
   "source": [
    "#### 1)Создание мешка слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd92c138-5cf8-4dc0-b05d-1d6dd80c3068",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_reviews  = [\n",
    "    \"Отличное качество, всегда покупаю этот бренд.\",\n",
    "    \"Не понравился товар, бракованный.\",\n",
    "    \"Быстрая доставка, все пришло в целости и сохранности.\",\n",
    "    \"Удобный в использовании, рекомендую!\",\n",
    "    \"Цена слишком высокая, не соответствует качеству.\",\n",
    "    \"Надежный продукт, пользуюсь уже много лет.\",\n",
    "    \"Отвратительный опыт, товар пришел поврежденный.\",\n",
    "    \"Прекрасный выбор, доволен покупкой.\",\n",
    "    \"Не оправдал ожидания, не советую.\",\n",
    "    \"Отличный сервис, оперативная поддержка.\",\n",
    "    \"Эффективный продукт, рекомендую для использования.\",\n",
    "    \"Продукция этой компании всегда высокого качества.\",\n",
    "    \"Недовольство качеством, не стоит своих денег.\",\n",
    "    \"Хорошее соотношение цены и качества.\",\n",
    "    \"Надежный бренд, доволен покупкой.\",\n",
    "    \"Неудачный опыт, не буду больше покупать у этого производителя.\",\n",
    "    \"Инновационный продукт, радует новыми возможностями.\",\n",
    "    \"Необычный дизайн, отличается от других аналогов.\",\n",
    "    \"Низкое качество, не рекомендую к покупке.\",\n",
    "    \"Отличный выбор для повседневного использования.\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16950b9e-107c-4c0f-abb5-87d9f8e6ac13",
   "metadata": {},
   "source": [
    "#### 2) Создание словаря стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a5a76d05-d529-404b-9b0a-b7633254e6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "custom_stop_words = set([\"всегда\", \"не\", \"и\", \"в\", \"все\", \"целости\", \"и\", \"в\", \"с\", \"не\", \n",
    "    \"для\", \"поддержка\", \"этой\", \"это\", \"не\", \"не\", \"и\", \"больше\", \"у\", \n",
    "    \"не\", \"для\", \"по\", \"не\", \"от\", \"не\", \"не\", \"для\", \"не\", \"не\", \"и\", \n",
    "    \"для\", \"для\", \"по\", \"не\", \"не\", \"не\", \"не\", \"и\", \"не\", \"не\", \"для\", \n",
    "    \"не\", \"не\", \"не\", \"не\", \"для\", \"повседневного\", \"использования\"])\n",
    "\n",
    "text_custom = [\" \".join(doc.split()) for doc in custom_reviews]\n",
    "text_custom_no_stop = [\" \".join([word for word in doc.split() if word.lower() not in custom_stop_words]) for doc in text_custom]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de85bd8b-d19a-49a4-ad6a-f0d202659af9",
   "metadata": {},
   "source": [
    "#### 3) Масштабирование данных с помощью tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "659be8f0-2223-444d-9b94-512499dbd76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000)\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(text_custom_no_stop)\n",
    "y_custom = np.array([1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1])  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f036fafb-eab9-4bdf-bb55-9f5cc7085da2",
   "metadata": {},
   "source": [
    "#### 4) Исследование коэффициентов модели и Выводы по работе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d5c2a4e-aede-4c4a-8ad6-e91a02681580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "аналогов: 0.12998105828096523\n",
      "бракованный: -0.29983249540965473\n",
      "бренд: 0.24962664447065883\n",
      "буду: -0.21048350354057407\n",
      "быстрая: 0.14532324105180014\n",
      "возможностями: 0.1288524336407127\n",
      "выбор: 0.2713085255272981\n",
      "высокая: -0.23267661182414337\n",
      "высокого: 0.14461041393197804\n",
      "денег: -0.23267661182414337\n",
      "дизайн: 0.12998105828096523\n",
      "доволен: 0.2505823567041045\n",
      "доставка: 0.14532324105180014\n",
      "других: 0.12998105828096523\n",
      "инновационный: 0.1288524336407127\n",
      "использовании: 0.18527826844757248\n",
      "использования: 0.2829560778834268\n",
      "качества: 0.25422953466683273\n",
      "качество: -0.14068484555254232\n",
      "качеством: -0.23267661182414337\n",
      "качеству: -0.23267661182414337\n",
      "компании: 0.14461041393197804\n",
      "лет: 0.11606292733139123\n",
      "много: 0.11606292733139123\n",
      "надежный: 0.22773011851668265\n",
      "недовольство: -0.23267661182414337\n",
      "необычный: 0.12998105828096523\n",
      "неудачный: -0.21048350354057407\n",
      "низкое: -0.3010214488658573\n",
      "новыми: 0.1288524336407127\n",
      "ожидания: -0.300384214215625\n",
      "оперативная: 0.14386210064398425\n",
      "оправдал: -0.300384214215625\n",
      "опыт: -0.38428358848851946\n",
      "отвратительный: -0.2266915781934731\n",
      "отличается: 0.12998105828096523\n",
      "отличное: 0.14097321705069107\n",
      "отличный: 0.2728921861912119\n",
      "поврежденный: -0.2266915781934731\n",
      "поддержка: 0.14386210064398425\n",
      "покупать: -0.21048350354057407\n",
      "покупаю: 0.14097321705069107\n",
      "покупке: -0.3010214488658573\n",
      "покупкой: 0.2505823567041045\n",
      "пользуюсь: 0.11606292733139123\n",
      "понравился: -0.29983249540965473\n",
      "прекрасный: 0.14206047028316504\n",
      "пришел: -0.2266915781934731\n",
      "пришло: 0.14532324105180014\n",
      "продукт: 0.3174497849595068\n",
      "продукция: 0.14461041393197804\n",
      "производителя: -0.21048350354057407\n",
      "радует: 0.1288524336407127\n",
      "рекомендую: 0.03138433802348105\n",
      "своих: -0.23267661182414337\n",
      "сервис: 0.14386210064398425\n",
      "слишком: -0.23267661182414337\n",
      "советую: -0.300384214215625\n",
      "соответствует: -0.23267661182414337\n",
      "соотношение: 0.14461041393197802\n",
      "сохранности: 0.14532324105180014\n",
      "стоит: -0.23267661182414337\n",
      "товар: -0.4628227199666707\n",
      "удобный: 0.18527826844757248\n",
      "уже: 0.11606292733139123\n",
      "хорошее: 0.14461041393197802\n",
      "цена: -0.23267661182414337\n",
      "цены: 0.14461041393197802\n",
      "этого: -0.21048350354057407\n",
      "этот: 0.14097321705069107\n",
      "эффективный: 0.15531115234669082\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_tfidf, y_custom)  \n",
    "\n",
    "coefficients = model.coef_[0]\n",
    "feature_names_tfidf = np.array(tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "for i, word in enumerate(feature_names_tfidf):\n",
    "    print(f\"{word}: {coefficients[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37ebb50-7b61-4f1b-a4a8-d49d1786fe41",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Знак коэффициента указывает на направление влияния: \n",
    "##положительный для положительного влияния, отрицательный - для отрицательного."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
